{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于深度学习的文本分类\n",
    "\n",
    "使用基于mindspore框架的自然语言处理库mindnlp\n",
    "\n",
    "主仓库地址：https://github.com/mindspore-lab/mindnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造数据集\n",
    "\n",
    "根据所提供的news20数据集，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "news20 load function\n",
    "\"\"\"\n",
    "import os\n",
    "import mindspore\n",
    "from tqdm import tqdm\n",
    "from mindspore.dataset import GeneratorDataset\n",
    "\n",
    "mindspore.set_context(device_target=\"GPU\") # set GPU\n",
    "\n",
    "label_dict = {}\n",
    "label_count = 0\n",
    "\n",
    "class News20:\n",
    "    \"\"\"\n",
    "    NEWS dataset source\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path)->None:\n",
    "        self.path: str = path\n",
    "        self._text, self._label = [], []\n",
    "        self.label_dict = {}\n",
    "        self.label_count = 0\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        labels = os.listdir(self.path)\n",
    "        for label in labels:\n",
    "            self.label_dict[label] = self.label_count\n",
    "            self.label_count += 1\n",
    "            label_path = os.path.join(self.path, label)\n",
    "            with tqdm(total = len(os.listdir(label_path)), desc = label) as pbar:\n",
    "                for t in os.listdir(label_path):\n",
    "                    pbar.update(1)\n",
    "                    text_path = os.path.join(label_path, t)\n",
    "                    file = open(text_path, \"r\" ,encoding=\"latin-1\") # latin-1\n",
    "                    text = file.read().strip()\n",
    "                    begin = text.find('\\n\\n')\n",
    "                    if 0 < begin: # skip head\n",
    "                        text = text[begin:]\n",
    "                    self._text.append(text)\n",
    "                    self._label.append(self.label_dict[label])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self._text[index], self._label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "def news20(source:News20):\n",
    "    r\"\"\"\n",
    "    Load the news20 dataset\n",
    "    \"\"\"\n",
    "    column_names = [\"text\", \"label\"]\n",
    "    return GeneratorDataset(source = source, column_names = column_names, shuffle = False) # 不shuffle，划分数据集时会进行打乱\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sci.electronics: 100%|██████████| 1000/1000 [00:01<00:00, 592.42it/s]\n",
      "misc.forsale: 100%|██████████| 1000/1000 [00:01<00:00, 512.24it/s]\n",
      "rec.sport.hockey: 100%|██████████| 1000/1000 [00:01<00:00, 527.84it/s]\n",
      "rec.autos: 100%|██████████| 1000/1000 [00:01<00:00, 519.68it/s]\n",
      "alt.atheism: 100%|██████████| 1000/1000 [00:01<00:00, 512.65it/s]\n",
      "comp.sys.mac.hardware: 100%|██████████| 1000/1000 [00:01<00:00, 537.87it/s]\n",
      "talk.politics.mideast: 100%|██████████| 1000/1000 [00:01<00:00, 502.31it/s]\n",
      "sci.med: 100%|██████████| 1000/1000 [00:02<00:00, 490.26it/s]\n",
      "rec.motorcycles: 100%|██████████| 1000/1000 [00:01<00:00, 510.67it/s]\n",
      "soc.religion.christian: 100%|██████████| 997/997 [00:02<00:00, 494.56it/s]\n",
      "talk.politics.guns: 100%|██████████| 1000/1000 [00:01<00:00, 532.21it/s]\n",
      "sci.crypt: 100%|██████████| 1000/1000 [00:01<00:00, 516.19it/s]\n",
      "rec.sport.baseball: 100%|██████████| 1000/1000 [00:02<00:00, 499.90it/s]\n",
      "comp.windows.x: 100%|██████████| 1000/1000 [00:02<00:00, 468.16it/s]\n",
      "talk.religion.misc: 100%|██████████| 1000/1000 [00:01<00:00, 536.50it/s]\n",
      "sci.space: 100%|██████████| 1000/1000 [00:02<00:00, 495.60it/s]\n",
      "comp.os.ms-windows.misc: 100%|██████████| 1000/1000 [00:01<00:00, 528.41it/s]\n",
      "comp.graphics: 100%|██████████| 1000/1000 [00:01<00:00, 525.91it/s]\n",
      "talk.politics.misc: 100%|██████████| 1000/1000 [00:01<00:00, 505.98it/s]\n",
      "comp.sys.ibm.pc.hardware: 100%|██████████| 1000/1000 [00:01<00:00, 541.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sci.electronics': 0, 'misc.forsale': 1, 'rec.sport.hockey': 2, 'rec.autos': 3, 'alt.atheism': 4, 'comp.sys.mac.hardware': 5, 'talk.politics.mideast': 6, 'sci.med': 7, 'rec.motorcycles': 8, 'soc.religion.christian': 9, 'talk.politics.guns': 10, 'sci.crypt': 11, 'rec.sport.baseball': 12, 'comp.windows.x': 13, 'talk.religion.misc': 14, 'sci.space': 15, 'comp.os.ms-windows.misc': 16, 'comp.graphics': 17, 'talk.politics.misc': 18, 'comp.sys.ibm.pc.hardware': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 载入数据\n",
    "dataset_source = News20(r\"/run/determined/workdir/qishunheng/lijiaming/nlp_ex/dataset/20_newsgroup\")\n",
    "print(dataset_source.label_dict)\n",
    "dataset = news20(dataset_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Models & Loss & Optimizer\n",
    "hidden_size = 256\n",
    "output_size = 20\n",
    "num_layers = 2\n",
    "bidirectional = False\n",
    "drop = 0.5\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "import mindspore\n",
    "from mindspore.dataset import text, transforms\n",
    "from mindnlp.modules import Glove\n",
    "from mindnlp.dataset.transforms import BasicTokenizer\n",
    "from mindnlp.dataset import process\n",
    "\n",
    "def data_process(dataset, tokenizer, vocab, batch_size = 64, max_len = 1000, drop_remainder = False):\n",
    "    \"\"\"\n",
    "    预处理\n",
    "    \"\"\"\n",
    "    # print(\"!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    dataset = dataset.map([tokenizer], 'text')\n",
    "    lookup_op = text.Lookup(vocab, unknown_token = '<unk>')\n",
    "    dataset = dataset.map([lookup_op], 'text')\n",
    "    pad_value = vocab.tokens_to_ids('<pad>')\n",
    "    pad_op = transforms.PadEnd([max_len], pad_value)\n",
    "    dataset = dataset.map([pad_op], 'text')\n",
    "    onehot_op = transforms.OneHot(num_classes=20)\n",
    "    dataset = dataset.map([onehot_op], 'label')\n",
    "    type_cast_op = transforms.TypeCast(mindspore.float32)\n",
    "    dataset = dataset.map([type_cast_op], 'label')\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder = drop_remainder)\n",
    "    return dataset\n",
    "\n",
    "tokenizer = BasicTokenizer(True)\n",
    "embedding, vocab = Glove.from_pretrained('6B', 100, special_tokens=[\"<unk>\", \"<pad>\"], dropout=drop, root = r\"/run/determined/workdir/qishunheng/lijiaming\")\n",
    "\n",
    "dataset_process = data_process(dataset, tokenizer, vocab) # 其余使用默认参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "train_dataset, test_dataset = dataset_process.split([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建网络\n",
    "import math\n",
    "\n",
    "from mindspore import nn\n",
    "from mindspore import ops\n",
    "from mindspore.common.initializer import Uniform, HeUniform\n",
    "from mindnlp.abc import Seq2vecModel\n",
    "\n",
    "class Head(nn.Cell):\n",
    "    \"\"\"\n",
    "    Head for Classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        weight_init = HeUniform(math.sqrt(5))\n",
    "        bias_init = Uniform(10 / math.sqrt(hidden_dim * 2))\n",
    "        self.fc = nn.Dense(hidden_dim * 2, output_dim, weight_init=weight_init, bias_init=bias_init)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "    def construct(self, context):\n",
    "        context = ops.concat((context[-2, :, :], context[-1, :, :]), axis=1)\n",
    "        context = self.dropout(context)\n",
    "        return self.softmax(self.fc(context))\n",
    "\n",
    "\n",
    "class Classification(Seq2vecModel):\n",
    "    \"\"\"\n",
    "    Classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, head):\n",
    "        super().__init__(encoder, head)\n",
    "        self.encoder = encoder\n",
    "        self.head = head\n",
    "\n",
    "    def construct(self, text):\n",
    "        _, (hidden, _), _ = self.encoder(text)\n",
    "        output = self.head(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/250 [00:00<?, ?it/s][WARNING] ME(77922:139915739633472,MainProcess):2022-12-16-17:41:24.259.811 [mindspore/ops/primitive.py:710] The \"_check_is_tensor\" is a constexpr function. The input arguments must be all constant value.\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda-11.1/lib64/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "Epoch 0:   2%|▏         | 4/250 [00:06<03:47,  1.08it/s, loss=3.008973] [WARNING] ME(77922:139915739633472,MainProcess):2022-12-16-17:41:26.493.176 [mindspore/ops/primitive.py:710] The \"_check_is_tensor\" is a constexpr function. The input arguments must be all constant value.\n",
      "Epoch 0:  45%|████▍     | 112/250 [00:19<00:15,  8.83it/s, loss=2.9969065]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from mindnlp.modules import RNNEncoder\n",
    "from mindnlp.engine.metrics import Accuracy\n",
    "from mindnlp.engine.trainer import Trainer\n",
    "\n",
    "lstm_layer = nn.LSTM(100, hidden_size, num_layers=num_layers, batch_first=True,\n",
    "                     dropout=drop, bidirectional=bidirectional)\n",
    "encoder = RNNEncoder(embedding, lstm_layer)\n",
    "head = Head(hidden_size, output_size, drop)\n",
    "\n",
    "net = Classification(encoder, head)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = nn.Adam(net.trainable_params(), learning_rate=lr)\n",
    "\n",
    "# define metrics\n",
    "metric = Accuracy()\n",
    "\n",
    "# define trainer\n",
    "trainer = Trainer(network=net, train_dataset = train_dataset, eval_dataset = test_dataset, metrics=metric,\n",
    "                  epochs=5, loss_fn=loss, optimizer=optimizer)\n",
    "trainer.run(tgt_columns=\"label\", jit=True)\n",
    "print(\"end train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('mindspore_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88945c05160fc4aa49701ecdecc59f11e0dfb59f137b2270bc666d6ef899be17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
