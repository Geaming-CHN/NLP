{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于深度学习的文本分类\n",
    "\n",
    "使用基于mindspore框架的自然语言处理库mindnlp\n",
    "\n",
    "主仓库地址：https://github.com/mindspore-lab/mindnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造数据集\n",
    "\n",
    "根据所提供的news20数据集，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "news20 load function\n",
    "\"\"\"\n",
    "import os\n",
    "import mindspore\n",
    "from tqdm import tqdm\n",
    "from mindspore.dataset import GeneratorDataset\n",
    "\n",
    "# mindspore.set_context(device_target=\"GPU\") # set GPU\n",
    "\n",
    "label_dict = {}\n",
    "label_count = 0\n",
    "\n",
    "class News20:\n",
    "    \"\"\"\n",
    "    NEWS dataset source\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path)->None:\n",
    "        self.path: str = path\n",
    "        self._text, self._label = [], []\n",
    "        self.label_dict = {}\n",
    "        self.label_count = 0\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        labels = os.listdir(self.path)\n",
    "        for label in labels:\n",
    "            self.label_dict[label] = self.label_count\n",
    "            self.label_count += 1\n",
    "            label_path = os.path.join(self.path, label)\n",
    "            with tqdm(total = len(os.listdir(label_path)), desc = label) as pbar:\n",
    "                for t in os.listdir(label_path):\n",
    "                    pbar.update(1)\n",
    "                    text_path = os.path.join(label_path, t)\n",
    "                    file = open(text_path, \"r\" ,encoding=\"latin-1\") # latin-1\n",
    "                    text = file.read().strip()\n",
    "                    begin = text.find('\\n\\n')\n",
    "                    if 0 < begin: # skip head\n",
    "                        text = text[begin:]\n",
    "                    self._text.append(text)\n",
    "                    self._label.append(self.label_dict[label])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self._text[index], self._label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "def news20(source:News20):\n",
    "    r\"\"\"\n",
    "    Load the news20 dataset\n",
    "    \"\"\"\n",
    "    column_names = [\"text\", \"label\"]\n",
    "    return GeneratorDataset(source = source, column_names = column_names, shuffle = False) # 不shuffle，划分数据集时会进行打乱\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alt.atheism: 100%|██████████| 1000/1000 [00:00<00:00, 3956.62it/s]\n",
      "comp.graphics: 100%|██████████| 1000/1000 [00:00<00:00, 4370.14it/s]\n",
      "comp.os.ms-windows.misc: 100%|██████████| 1000/1000 [00:00<00:00, 4282.78it/s]\n",
      "comp.sys.ibm.pc.hardware: 100%|██████████| 1000/1000 [00:00<00:00, 4331.89it/s]\n",
      "comp.sys.mac.hardware: 100%|██████████| 1000/1000 [00:00<00:00, 4321.41it/s]\n",
      "comp.windows.x: 100%|██████████| 1000/1000 [00:00<00:00, 4431.71it/s]\n",
      "misc.forsale: 100%|██████████| 1000/1000 [00:00<00:00, 4657.28it/s]\n",
      "rec.autos: 100%|██████████| 1000/1000 [00:00<00:00, 4489.05it/s]\n",
      "rec.motorcycles: 100%|██████████| 1000/1000 [00:00<00:00, 4602.28it/s]\n",
      "rec.sport.baseball: 100%|██████████| 1000/1000 [00:00<00:00, 4663.45it/s]\n",
      "rec.sport.hockey: 100%|██████████| 1000/1000 [00:00<00:00, 4627.30it/s]\n",
      "sci.crypt: 100%|██████████| 1000/1000 [00:00<00:00, 4484.09it/s]\n",
      "sci.electronics: 100%|██████████| 1000/1000 [00:00<00:00, 4164.30it/s]\n",
      "sci.med: 100%|██████████| 1000/1000 [00:00<00:00, 3928.48it/s]\n",
      "sci.space: 100%|██████████| 1000/1000 [00:00<00:00, 3834.51it/s]\n",
      "soc.religion.christian: 100%|██████████| 997/997 [00:00<00:00, 4030.88it/s]\n",
      "talk.politics.guns: 100%|██████████| 1000/1000 [00:00<00:00, 4083.27it/s]\n",
      "talk.politics.mideast: 100%|██████████| 1000/1000 [00:00<00:00, 3976.66it/s]\n",
      "talk.politics.misc: 100%|██████████| 1000/1000 [00:00<00:00, 3801.36it/s]\n",
      "talk.religion.misc: 100%|██████████| 1000/1000 [00:00<00:00, 4021.22it/s]\n",
      "[WARNING] ME(32880:30932,MainProcess):2022-12-17-01:57:52.754.686 [mindspore\\dataset\\engine\\datasets_user_defined.py:657] Python multiprocessing is not supported on Windows platform.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alt.atheism': 0, 'comp.graphics': 1, 'comp.os.ms-windows.misc': 2, 'comp.sys.ibm.pc.hardware': 3, 'comp.sys.mac.hardware': 4, 'comp.windows.x': 5, 'misc.forsale': 6, 'rec.autos': 7, 'rec.motorcycles': 8, 'rec.sport.baseball': 9, 'rec.sport.hockey': 10, 'sci.crypt': 11, 'sci.electronics': 12, 'sci.med': 13, 'sci.space': 14, 'soc.religion.christian': 15, 'talk.politics.guns': 16, 'talk.politics.mideast': 17, 'talk.politics.misc': 18, 'talk.religion.misc': 19}\n"
     ]
    }
   ],
   "source": [
    "# 载入数据\n",
    "dataset_source = News20(r\"G:\\_CQU\\3-1\\自然语言处理\\实验\\实验二\\NLP\\news20\\20_newsgroup\")\n",
    "print(dataset_source.label_dict)\n",
    "dataset = news20(dataset_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Models & Loss & Optimizer\n",
    "hidden_size = 256\n",
    "output_size = 20\n",
    "num_layers = 2\n",
    "bidirectional = False\n",
    "drop = 0.5\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "import mindspore\n",
    "from mindspore.dataset import text, transforms\n",
    "from mindnlp.modules import Glove\n",
    "from mindnlp.dataset.transforms import BasicTokenizer\n",
    "from mindnlp.dataset import process\n",
    "\n",
    "def data_process(dataset, tokenizer, vocab, batch_size = 64, max_len = 1000, drop_remainder = False):\n",
    "    \"\"\"\n",
    "    预处理\n",
    "    \"\"\"\n",
    "    # print(\"!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    dataset = dataset.map([tokenizer], 'text')\n",
    "    lookup_op = text.Lookup(vocab, unknown_token = '<unk>')\n",
    "    dataset = dataset.map([lookup_op], 'text')\n",
    "    pad_value = vocab.tokens_to_ids('<pad>')\n",
    "    pad_op = transforms.PadEnd([max_len], pad_value)\n",
    "    dataset = dataset.map([pad_op], 'text')\n",
    "    onehot_op = transforms.OneHot(num_classes=20)\n",
    "    dataset = dataset.map([onehot_op], 'label')\n",
    "    type_cast_op = transforms.TypeCast(mindspore.float32)\n",
    "    dataset = dataset.map([type_cast_op], 'label')\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder = drop_remainder)\n",
    "    return dataset\n",
    "\n",
    "tokenizer = BasicTokenizer(True)\n",
    "embedding, vocab = Glove.from_pretrained('6B', 100, special_tokens=[\"<unk>\", \"<pad>\"], dropout=drop)\n",
    "\n",
    "dataset_process = data_process(dataset, tokenizer, vocab) # 其余使用默认参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "train_dataset, test_dataset = dataset_process.split([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建网络\n",
    "import math\n",
    "\n",
    "from mindspore import nn\n",
    "from mindspore import ops\n",
    "from mindspore.common.initializer import Uniform, HeUniform\n",
    "from mindnlp.abc import Seq2vecModel\n",
    "\n",
    "class Head(nn.Cell):\n",
    "    \"\"\"\n",
    "    Head for Classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        weight_init = HeUniform(math.sqrt(5))\n",
    "        bias_init = Uniform(10 / math.sqrt(hidden_dim * 2))\n",
    "        self.fc = nn.Dense(hidden_dim * 2, output_dim, weight_init=weight_init, bias_init=bias_init)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "    def construct(self, context):\n",
    "        context = ops.concat((context[-2, :, :], context[-1, :, :]), axis=1)\n",
    "        context = self.dropout(context)\n",
    "        return self.softmax(self.fc(context))\n",
    "\n",
    "\n",
    "class Classification(Seq2vecModel):\n",
    "    \"\"\"\n",
    "    Classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, head):\n",
    "        super().__init__(encoder, head)\n",
    "        self.encoder = encoder\n",
    "        self.head = head\n",
    "\n",
    "    def construct(self, text):\n",
    "        _, (hidden, _), _ = self.encoder(text)\n",
    "        output = self.head(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from mindnlp.modules import RNNEncoder\n",
    "from mindnlp.engine.metrics import Accuracy\n",
    "from mindnlp.engine.trainer import Trainer\n",
    "\n",
    "lstm_layer = nn.LSTM(100, hidden_size, num_layers=num_layers, batch_first=True,\n",
    "                     dropout=drop, bidirectional=bidirectional)\n",
    "encoder = RNNEncoder(embedding, lstm_layer)\n",
    "head = Head(hidden_size, output_size, drop)\n",
    "\n",
    "net = Classification(encoder, head)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = nn.Adam(net.trainable_params(), learning_rate=lr)\n",
    "\n",
    "# define metrics\n",
    "metric = Accuracy()\n",
    "\n",
    "# define trainer\n",
    "trainer = Trainer(network=net, train_dataset = train_dataset, eval_dataset = test_dataset, metrics=metric,\n",
    "                  epochs=5, loss_fn=loss, optimizer=optimizer)\n",
    "trainer.run(tgt_columns=\"label\", jit=False)\n",
    "print(\"end train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('1216')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77f8c42b9048a804c9b54fe3fdcc803144c07769274c7f5b50f37195cc1e314b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
