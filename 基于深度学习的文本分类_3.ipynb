{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于深度学习的文本分类\n",
    "\n",
    "使用基于mindspore框架的自然语言处理库mindnlp\n",
    "\n",
    "主仓库地址：https://github.com/mindspore-lab/mindnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造数据集\n",
    "\n",
    "根据所提供的news20数据集，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindspore.set_context(device_target=\"GPU\") # set GPU\n",
    "\"\"\"\n",
    "news20 load function\n",
    "\"\"\"\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from mindspore.dataset import GeneratorDataset\n",
    "import mindspore\n",
    "import numpy as np\n",
    "\n",
    "label_dict = {}\n",
    "label_count = 0\n",
    "\n",
    "class News20:\n",
    "    \"\"\"\n",
    "    NEWS dataset source\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path)->None:\n",
    "        self.path: str = path\n",
    "        self._text, self._label = [], []\n",
    "        self.label_dict = {}\n",
    "        self.label_count = 0\n",
    "        self._load()\n",
    "\n",
    "    def _load(self):\n",
    "        labels = os.listdir(self.path)\n",
    "        for label in labels:\n",
    "            label_path = os.path.join(self.path, label)\n",
    "            if not os.path.isdir(label_path):      # 如果不是一个文件夹就不算\n",
    "                continue\n",
    "            self.label_dict[label] = self.label_count\n",
    "            self.label_count += 1\n",
    "            \n",
    "            with tqdm(total = len(os.listdir(label_path)), desc = label) as pbar:\n",
    "                for t in os.listdir(label_path):\n",
    "                    pbar.update(1)\n",
    "                    if not t.isdigit():\n",
    "                        continue\n",
    "                    text_path = os.path.join(label_path, t)\n",
    "                    import sys\n",
    "                    args = {} if sys.version_info < (3,) else {'encoding': 'latin-1'}\n",
    "                    with open(text_path, **args) as file: # latin-1\n",
    "                        text = file.read().strip()\n",
    "                        begin = text.find('\\n\\n')\n",
    "                        if 0 < begin: # skip head\n",
    "                            text = text[begin:]\n",
    "                        if type(text) is str and len(text) > 0:\n",
    "                            self._text.append(text)\n",
    "                            self._label.append(self.label_dict[label])\n",
    "        for x in self._text:\n",
    "            if type(x) is not str:\n",
    "                print(\"!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # print(index)\n",
    "        # if type(self._text[index]) is not str:\n",
    "        #     print(\"Nope!\") \n",
    "        #     print(type(self._text[index]))\n",
    "        return np.array(self._text[index], dtype=str), np.array(self._label[index], dtype=int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "def news20(source:News20):\n",
    "    r\"\"\"\n",
    "    Load the news20 dataset\n",
    "    \"\"\"\n",
    "    column_names = [\"text\", \"label\"]\n",
    "    return GeneratorDataset(source = source, shuffle=False, column_names = column_names, column_types = [mindspore.string, mindspore.int32], python_multiprocessing=False) # 不shuffle，划分数据集时会进行打乱\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alt.atheism: 100%|██████████| 1000/1000 [00:00<00:00, 13368.90it/s]\n",
      "comp.graphics: 100%|██████████| 1000/1000 [00:00<00:00, 11936.46it/s]\n",
      "comp.os.ms-windows.misc: 100%|██████████| 1000/1000 [00:00<00:00, 13735.29it/s]\n",
      "comp.sys.ibm.pc.hardware: 100%|██████████| 1000/1000 [00:00<00:00, 13818.46it/s]\n",
      "comp.sys.mac.hardware: 100%|██████████| 1000/1000 [00:00<00:00, 14122.05it/s]\n",
      "comp.windows.x: 100%|██████████| 1000/1000 [00:00<00:00, 12532.66it/s]\n",
      "misc.forsale: 100%|██████████| 1000/1000 [00:00<00:00, 14122.14it/s]\n",
      "rec.autos: 100%|██████████| 1000/1000 [00:00<00:00, 13191.79it/s]\n",
      "rec.motorcycles: 100%|██████████| 1000/1000 [00:00<00:00, 13549.94it/s]\n",
      "rec.sport.baseball: 100%|██████████| 1000/1000 [00:00<00:00, 14122.24it/s]\n",
      "rec.sport.hockey: 100%|██████████| 1000/1000 [00:00<00:00, 13926.01it/s]\n",
      "sci.crypt: 100%|██████████| 1000/1000 [00:00<00:00, 14324.03it/s]\n",
      "sci.electronics: 100%|██████████| 1000/1000 [00:00<00:00, 14203.58it/s]\n",
      "sci.med: 100%|██████████| 1000/1000 [00:00<00:00, 14122.33it/s]\n",
      "sci.space: 100%|██████████| 1000/1000 [00:00<00:00, 14122.19it/s]\n",
      "soc.religion.christian: 100%|██████████| 997/997 [00:00<00:00, 13883.63it/s]\n",
      "talk.politics.guns: 100%|██████████| 1000/1000 [00:00<00:00, 14324.07it/s]\n",
      "talk.politics.mideast: 100%|██████████| 1000/1000 [00:00<00:00, 13822.97it/s]\n",
      "talk.politics.misc: 100%|██████████| 1000/1000 [00:00<00:00, 13925.91it/s]\n",
      "talk.religion.misc: 100%|██████████| 1000/1000 [00:00<00:00, 14122.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alt.atheism': 0, 'comp.graphics': 1, 'comp.os.ms-windows.misc': 2, 'comp.sys.ibm.pc.hardware': 3, 'comp.sys.mac.hardware': 4, 'comp.windows.x': 5, 'misc.forsale': 6, 'rec.autos': 7, 'rec.motorcycles': 8, 'rec.sport.baseball': 9, 'rec.sport.hockey': 10, 'sci.crypt': 11, 'sci.electronics': 12, 'sci.med': 13, 'sci.space': 14, 'soc.religion.christian': 15, 'talk.politics.guns': 16, 'talk.politics.mideast': 17, 'talk.politics.misc': 18, 'talk.religion.misc': 19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 载入数据\n",
    "dataset_source = News20(r\"G:\\_CQU\\3-1\\自然语言处理\\实验\\实验二\\NLP\\news20\\20_newsgroup\")\n",
    "print(dataset_source.label_dict)\n",
    "dataset = news20(dataset_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19997\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Models & Loss & Optimizer\n",
    "hidden_size = 256\n",
    "output_size = 20\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "drop = 0.5\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "import mindspore\n",
    "from mindspore.dataset import text, transforms\n",
    "from mindnlp.modules import Glove\n",
    "from mindnlp.dataset.transforms import BasicTokenizer\n",
    "from mindnlp.dataset import process\n",
    "\n",
    "tokenizer = BasicTokenizer(True)\n",
    "embedding, vocab = Glove.from_pretrained('6B', 100, special_tokens=[\"<unk>\", \"<pad>\"], dropout=drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(dataset, tokenizer, vocab, batch_size = 64, max_len = 1000, drop_remainder = False):\n",
    "    \"\"\"\n",
    "    预处理\n",
    "    \"\"\"\n",
    "    # print(\"!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    dataset = dataset.map([tokenizer], 'text')\n",
    "\n",
    "    lookup_op = text.Lookup(vocab, unknown_token = '<unk>')\n",
    "    dataset = dataset.map([lookup_op], 'text')\n",
    "\n",
    "    pad_value = vocab.tokens_to_ids('<pad>')\n",
    "    pad_op = transforms.PadEnd([max_len], pad_value)\n",
    "    dataset = dataset.map([pad_op], 'text')\n",
    "\n",
    "    onehot_op = transforms.OneHot(num_classes=20)\n",
    "    dataset = dataset.map([onehot_op], 'label')\n",
    "\n",
    "    type_cast_op = transforms.TypeCast(mindspore.float32)\n",
    "    dataset = dataset.map([type_cast_op], 'label')\n",
    "    \n",
    "    dataset = dataset.batch(batch_size, drop_remainder = drop_remainder)\n",
    "    # print(\"bye!!!!!\")\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "dataset_process = data_process(dataset, tokenizer=tokenizer, vocab = vocab, batch_size=16)\n",
    "# print(\"hi\")\n",
    "\n",
    "# for x in dataset_p.create_dict_iterator():\n",
    "#     print(\"Done!\")\n",
    "\n",
    "# dataset_process = data_process(dataset, tokenizer, vocab) # 其余使用默认参数\n",
    "# dataset_process = process('imdb', dataset, tokenizer=tokenizer, vocab = vocab, max_len = 1000, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_t = dataset_process.create_dict_iterator()\n",
    "# print(type(iter_t))\n",
    "# print(next(iter_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "train_dataset, test_dataset = dataset_process.split([0.7, 0.3])\n",
    "# print(train_dataset.shape)\n",
    "# print(type(dataset_process))\n",
    "# train_iter = train_dataset.create_dict_iterator()\n",
    "# train_iter = iter(train_dataset)\n",
    "# train_dataset_p = data_process(train_dataset, tokenizer=tokenizer, vocab = vocab)\n",
    "# test_dataset_p = data_process(test_dataset, tokenizer=tokenizer, vocab = vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iter = train_dataset.create_dict_iterator()\n",
    "# print(type(train_iter))\n",
    "# for x in dataset.create_dict_iterator():\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mindspore.dataset.engine.datasets.TakeDataset at 0x2547f159f48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建网络\n",
    "import math\n",
    "\n",
    "from mindspore import nn\n",
    "from mindspore import ops\n",
    "from mindspore.common.initializer import Uniform, HeUniform\n",
    "from mindnlp.abc import Seq2vecModel\n",
    "\n",
    "class Head(nn.Cell):\n",
    "    \"\"\"\n",
    "    Head for Classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        weight_init = HeUniform(math.sqrt(5))\n",
    "        bias_init = Uniform(1 / math.sqrt(hidden_dim * 2))\n",
    "        self.fc = nn.Dense(hidden_dim * 2, output_dim, weight_init=weight_init, bias_init=bias_init)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "    def construct(self, context):\n",
    "        context = ops.concat((context[-2, :, :], context[-1, :, :]), axis=1)\n",
    "        context = self.dropout(context)\n",
    "        return self.softmax(self.fc(context))\n",
    "\n",
    "\n",
    "class Classification(Seq2vecModel):\n",
    "    \"\"\"\n",
    "    Classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, head):\n",
    "        super().__init__(encoder, head)\n",
    "        self.encoder = encoder\n",
    "        self.head = head\n",
    "\n",
    "    def construct(self, text):\n",
    "        _, (hidden, _), _ = self.encoder(text)\n",
    "        output = self.head(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   7%|▋         | 57/875 [08:12<1:57:44,  8.64s/it, loss=2.997643] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26816\\745194024.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m trainer = Trainer(network=net, train_dataset = train_dataset, eval_dataset = test_dataset, metrics=metric,\n\u001b[0;32m     20\u001b[0m                   epochs=5, loss_fn=loss, optimizer=optimizer)\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"end train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\_CQU\\3-1\\自然语言处理\\实验\\实验二\\NLP\\mindnlp\\engine\\trainer.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, tgt_columns, jit)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mrun_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRunContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\_CQU\\3-1\\自然语言处理\\实验\\实验二\\NLP\\mindnlp\\engine\\trainer.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, run_context, tgt_columns, jit)\u001b[0m\n\u001b[0;32m    213\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_step_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m                     \u001b[0mloss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_total\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcur_step_nums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mg:\\_CQU\\3-1\\自然语言处理\\实验\\实验二\\NLP\\mindnlp\\engine\\trainer.py\u001b[0m in \u001b[0;36m_run_step\u001b[1;34m(inputs, labels)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_run_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;34m\"\"\"Core process of each step, including the forward propagation process and back propagation of data.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda\\envs\\1216\\lib\\site-packages\\mindspore\\ops\\composite\\base.py\u001b[0m in \u001b[0;36mafter_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    555\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_by_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m                     \u001b[1;32mdef\u001b[0m \u001b[0mafter_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                     \u001b[1;32mdef\u001b[0m \u001b[0mafter_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda\\envs\\1216\\lib\\site-packages\\mindspore\\common\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*arg, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_convert_python_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda\\envs\\1216\\lib\\site-packages\\mindspore\\ops\\composite\\base.py\u001b[0m in \u001b[0;36mafter_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pynative_forward_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m                 \u001b[0m_pynative_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_position\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pynative_executor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msens_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m                 \u001b[0m_pynative_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda\\envs\\1216\\lib\\site-packages\\mindspore\\common\\api.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, sens_param, obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \"\"\"\n\u001b[0;32m    998\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msens_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda\\envs\\1216\\lib\\site-packages\\mindspore\\_extends\\parse\\parser.py\u001b[0m in \u001b[0;36mget_obj_id\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mget_obj_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m     \u001b[1;34m\"\"\"Get the obj id.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mindnlp.modules import RNNEncoder\n",
    "from mindnlp.engine.metrics import Accuracy\n",
    "from mindnlp.engine.trainer import Trainer\n",
    "\n",
    "\n",
    "lstm_layer = nn.LSTM(100, hidden_size, num_layers=num_layers, batch_first=True,\n",
    "                     dropout=drop, bidirectional=bidirectional)\n",
    "encoder = RNNEncoder(embedding, lstm_layer)\n",
    "head = Head(hidden_size, output_size, drop)\n",
    "\n",
    "net = Classification(encoder, head)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = nn.Adam(net.trainable_params(), learning_rate=lr)\n",
    "\n",
    "# define metrics\n",
    "metric = Accuracy()\n",
    "\n",
    "# define trainer\n",
    "trainer = Trainer(network=net, train_dataset = train_dataset, eval_dataset = test_dataset, metrics=metric,\n",
    "                  epochs=5, loss_fn=loss, optimizer=optimizer)\n",
    "trainer.run(tgt_columns=\"label\", jit=False)\n",
    "print(\"end train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.create_dict_iterator()\n",
    "next(train_dataset.create_dict_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"G:\\_CQU\\3-1\\自然语言处理\\实验\\实验二\\news20\\20_newsgroup\"\n",
    "LABELS = os.listdir(PATH)\n",
    "ALT = os.path.join(PATH,LABELS[0])\n",
    "TEXT_PATH = os.path.join(ALT,os.listdir(ALT)[0])\n",
    "TEXT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(TEXT_PATH, \"r\",encoding=\"latin-1\")\n",
    "text = file.read()\n",
    "begin = text.find('\\n\\n') # skip header\n",
    "if 0 < begin:\n",
    "    text = text[begin:]\n",
    "text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('1216')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77f8c42b9048a804c9b54fe3fdcc803144c07769274c7f5b50f37195cc1e314b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
